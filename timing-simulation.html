<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Timing Simulation - Loom Documentation</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Loom Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/ChipFlow/Loom" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="timing-simulation-in-gem"><a class="header" href="#timing-simulation-in-gem">Timing Simulation in GEM</a></h1>
<p>This document explains GEM's boomerang evaluation architecture and how timing simulation with per-gate delays can be implemented efficiently on GPU.</p>
<h2 id="background-the-simulation-challenge"><a class="header" href="#background-the-simulation-challenge">Background: The Simulation Challenge</a></h2>
<p>GEM simulates And-Inverter Graphs (AIGs) where every node is either:</p>
<ul>
<li>A <strong>primary input</strong> (value comes from VCD stimulus)</li>
<li>An <strong>AND gate</strong> with two inputs (possibly inverted)</li>
</ul>
<p>Traditional simulation evaluates gates in topological order, which is inherently serial. GPUs excel at massive parallelism - thousands of threads doing the same operation on different data. GEM bridges this gap with the <strong>boomerang</strong> architecture.</p>
<h2 id="boomerang-evaluation"><a class="header" href="#boomerang-evaluation">Boomerang Evaluation</a></h2>
<h3 id="core-concept"><a class="header" href="#core-concept">Core Concept</a></h3>
<p>The boomerang structure is a <strong>hierarchical reduction tree</strong> that maps an AIG onto GPU threads. It's called "boomerang" because data flows down the tree during reduction, then results are written back out at various levels - like a boomerang going out and returning.</p>
<h3 id="hierarchy-structure"><a class="header" href="#hierarchy-structure">Hierarchy Structure</a></h3>
<p>GEM uses <code>BOOMERANG_NUM_STAGES = 13</code>, meaning the tree has 2^13 = 8192 leaf positions:</p>
<pre><code>Level 0 (inputs):   8192 positions
Level 1:            4096 positions  (8192 / 2)
Level 2:            2048 positions
Level 3:            1024 positions
Level 4:             512 positions
Level 5:             256 positions
Level 6:             128 positions
Level 7:              64 positions
Level 8:              32 positions
Level 9:              16 positions
Level 10:              8 positions
Level 11:              4 positions
Level 12:              2 positions
Level 13 (output):     1 position
</code></pre>
<p>Each level halves the number of positions by computing AND gates that combine pairs.</p>
<h3 id="thread-organization"><a class="header" href="#thread-organization">Thread Organization</a></h3>
<p>A GPU block has <strong>256 threads</strong> (<code>threadIdx.x</code> = 0..255). Each thread holds a <strong>32-bit word</strong> where each bit represents an independent Boolean signal:</p>
<pre><code>Thread 0:   [bit0, bit1, bit2, ... bit31]  = 32 Boolean signals
Thread 1:   [bit0, bit1, bit2, ... bit31]  = 32 Boolean signals
...
Thread 255: [bit0, bit1, bit2, ... bit31]  = 32 Boolean signals
            ─────────────────────────────
            Total: 256 × 32 = 8192 signals per level
</code></pre>
<p><strong>Thread position</strong> refers to <code>threadIdx.x</code> - which of the 256 threads we're addressing. Each thread position processes 32 signals in parallel using SIMD operations.</p>
<h3 id="memory-layout"><a class="header" href="#memory-layout">Memory Layout</a></h3>
<pre><code class="language-cpp">__shared__ u32 shared_metadata[256];   // Partition configuration
__shared__ u32 shared_writeouts[256];  // Output staging area
__shared__ u32 shared_state[256];      // Working state (8192 bits)
</code></pre>
<p>The <code>shared_state</code> array holds the current level's values during reduction.</p>
<h2 id="the-reduction-process"><a class="header" href="#the-reduction-process">The Reduction Process</a></h2>
<h3 id="phase-1-level-0--level-1-hier0"><a class="header" href="#phase-1-level-0--level-1-hier0">Phase 1: Level 0 → Level 1 (hier[0])</a></h3>
<p>Only threads 128-255 are active. Each computes 32 AND gates in parallel:</p>
<pre><code class="language-cpp">if(threadIdx.x &gt;= 128) {
    u32 hier_input_a = shared_state[threadIdx.x - 128];  // From threads 0-127
    u32 hier_input_b = hier_input;                        // This thread's data

    // 32 AND gates computed simultaneously (one per bit)
    u32 ret = (hier_input_a ^ hier_flag_xora) &amp;
              ((hier_input_b ^ hier_flag_xorb) | hier_flag_orb);

    shared_state[threadIdx.x] = ret;
}
</code></pre>
<p>The <code>xora</code>, <code>xorb</code>, and <code>orb</code> flags encode:</p>
<ul>
<li><code>xora/xorb</code>: Input inversions (for AND-inverter graph)</li>
<li><code>orb</code>: Passthrough mode (when output equals input A, skip the AND)</li>
</ul>
<p>Visual representation:</p>
<pre><code>Before:  [T0][T1]...[T127] [T128][T129]...[T255]
              │                  │
              └───────┬──────────┘
                      │
                   AND gates (128 threads × 32 bits = 4096 gates)
                      │
                      ▼
After:   [----unused----] [T128][T129]...[T255]
                          (128 × 32 = 4096 results)
</code></pre>
<h3 id="phase-2-levels-1-3-shared-memory"><a class="header" href="#phase-2-levels-1-3-shared-memory">Phase 2: Levels 1-3 (Shared Memory)</a></h3>
<pre><code class="language-cpp">for(int hi = 1; hi &lt;= 3; ++hi) {
    int hier_width = 1 &lt;&lt; (7 - hi);  // 64, 32, 16
    if(threadIdx.x &gt;= hier_width &amp;&amp; threadIdx.x &lt; hier_width * 2) {
        u32 hier_input_a = shared_state[threadIdx.x + hier_width];
        u32 hier_input_b = shared_state[threadIdx.x + hier_width * 2];
        u32 ret = (hier_input_a ^ xora) &amp; ((hier_input_b ^ xorb) | orb);
        shared_state[threadIdx.x] = ret;
    }
    __syncthreads();  // Barrier between levels
}
</code></pre>
<p>Each level activates fewer threads:</p>
<ul>
<li>Level 1: threads 64-127 (64 threads → 2048 gates)</li>
<li>Level 2: threads 32-63 (32 threads → 1024 gates)</li>
<li>Level 3: threads 16-31 (16 threads → 512 gates)</li>
</ul>
<h3 id="phase-3-levels-4-7-warp-shuffle"><a class="header" href="#phase-3-levels-4-7-warp-shuffle">Phase 3: Levels 4-7 (Warp Shuffle)</a></h3>
<p>Within a single warp (32 threads), data exchange uses fast shuffle instructions instead of shared memory:</p>
<pre><code class="language-cpp">if(threadIdx.x &lt; 32) {
    for(int hi = 4; hi &lt;= 7; ++hi) {
        int hier_width = 1 &lt;&lt; (7 - hi);  // 8, 4, 2, 1
        u32 hier_input_a = __shfl_down_sync(0xffffffff, tmp_cur_hi, hier_width);
        u32 hier_input_b = __shfl_down_sync(0xffffffff, tmp_cur_hi, hier_width * 2);
        if(threadIdx.x &gt;= hier_width &amp;&amp; threadIdx.x &lt; hier_width * 2) {
            tmp_cur_hi = (hier_input_a ^ xora) &amp; ((hier_input_b ^ xorb) | orb);
        }
    }
}
</code></pre>
<p>No synchronization needed - warp shuffle is implicitly synchronized.</p>
<h3 id="phase-4-levels-8-12-bit-operations"><a class="header" href="#phase-4-levels-8-12-bit-operations">Phase 4: Levels 8-12 (Bit Operations)</a></h3>
<p>The final levels operate on bits within a single u32, computed by thread 0 only:</p>
<pre><code class="language-cpp">if(threadIdx.x == 0) {
    // Level 8: 32 → 16 (operates on upper/lower halves)
    u32 r8 = ((v1 &lt;&lt; 16) ^ xora) &amp; ((v1 ^ xorb) | orb) &amp; 0xffff0000;

    // Level 9: 16 → 8
    u32 r9 = ((r8 &gt;&gt; 8) ^ xora) &amp; (((r8 &gt;&gt; 16) ^ xorb) | orb) &amp; 0xff00;

    // Level 10: 8 → 4
    u32 r10 = ((r9 &gt;&gt; 4) ^ xora) &amp; (((r9 &gt;&gt; 8) ^ xorb) | orb) &amp; 0xf0;

    // Level 11: 4 → 2
    u32 r11 = ((r10 &gt;&gt; 2) ^ xora) &amp; (((r10 &gt;&gt; 4) ^ xorb) | orb) &amp; 0b1100;

    // Level 12: 2 → 1
    u32 r12 = ((r11 &gt;&gt; 1) ^ xora) &amp; (((r11 &gt;&gt; 2) ^ xorb) | orb) &amp; 0b10;

    tmp_cur_hi = r8 | r9 | r10 | r11 | r12;
}
</code></pre>
<h3 id="write-outs"><a class="header" href="#write-outs">Write-Outs</a></h3>
<p>Results are captured at various levels (not just the final output) and written to global memory:</p>
<pre><code class="language-cpp">if((writeout_hook_i &gt;&gt; 8) == bs_i) {
    shared_writeouts[threadIdx.x] = shared_state[writeout_hook_i &amp; 255];
}
</code></pre>
<p>This is the "return" part of the boomerang - results flow back from intermediate levels.</p>
<h2 id="timing-simulation-approaches"><a class="header" href="#timing-simulation-approaches">Timing Simulation Approaches</a></h2>
<h3 id="approach-comparison"><a class="header" href="#approach-comparison">Approach Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Approach</th><th>Parallelism</th><th>Memory</th><th>Accuracy</th><th>GPU Fit</th></tr></thead><tbody>
<tr><td>Event-driven</td><td>Poor (serial queue)</td><td>Low</td><td>Exact</td><td>Bad</td></tr>
<tr><td>Time-wheel</td><td>Medium</td><td>High</td><td>Configurable</td><td>Medium</td></tr>
<tr><td><strong>Levelized</strong></td><td><strong>Excellent</strong></td><td><strong>Low</strong></td><td><strong>Conservative</strong></td><td><strong>Best</strong></td></tr>
<tr><td>Oblivious</td><td>Maximum</td><td>Very High</td><td>Exact</td><td>Wasteful</td></tr>
</tbody></table>
</div>
<h3 id="recommended-levelized-with-delay-accumulation"><a class="header" href="#recommended-levelized-with-delay-accumulation">Recommended: Levelized with Delay Accumulation</a></h3>
<p>This approach piggybacks on the existing boomerang structure with minimal changes.</p>
<h4 id="data-structure-addition"><a class="header" href="#data-structure-addition">Data Structure Addition</a></h4>
<pre><code class="language-cpp">// Add to shared memory (256 bytes additional)
__shared__ u8 shared_arrival[256];  // One arrival time per thread position
</code></pre>
<p>Each thread position stores a single 8-bit arrival time representing the <strong>maximum arrival across all 32 bits</strong> in that position.</p>
<h4 id="modified-and-gate-evaluation"><a class="header" href="#modified-and-gate-evaluation">Modified AND Gate Evaluation</a></h4>
<pre><code class="language-cpp">// Current (value only):
u32 ret = (hier_input_a ^ xora) &amp; ((hier_input_b ^ xorb) | orb);
shared_state[threadIdx.x] = ret;

// With timing (add ~4 instructions):
u32 ret = (hier_input_a ^ xora) &amp; ((hier_input_b ^ xorb) | orb);
shared_state[threadIdx.x] = ret;

u8 arr_a = shared_arrival[threadIdx.x - offset_a];
u8 arr_b = shared_arrival[threadIdx.x - offset_b];
u8 arr_ret = min(max(arr_a, arr_b) + GATE_DELAY, 255);  // Saturating add
shared_arrival[threadIdx.x] = arr_ret;
</code></pre>
<h4 id="complexity-analysis"><a class="header" href="#complexity-analysis">Complexity Analysis</a></h4>
<ul>
<li><strong>Same number of kernel launches</strong> as zero-delay simulation</li>
<li><strong>O(levels × cycles)</strong> - identical to current</li>
<li><strong>~256 bytes additional shared memory</strong> per partition</li>
<li><strong>Estimated 10-20% performance overhead</strong></li>
</ul>
<h2 id="the-approximation-trade-off"><a class="header" href="#the-approximation-trade-off">The Approximation Trade-off</a></h2>
<h3 id="what-we-track"><a class="header" href="#what-we-track">What We Track</a></h3>
<p>One arrival time per thread position (256 values) instead of per signal (8192 values).</p>
<h3 id="implications"><a class="header" href="#implications">Implications</a></h3>
<p>If thread position 50 contains signals A, B, C with different true arrivals:</p>
<pre><code>Signal A: 15ps (shortest path)
Signal B: 23ps (longest path)
Signal C: 8ps  (medium path)
</code></pre>
<p>We store only: <code>arrival[50] = 23ps</code> (the maximum).</p>
<h3 id="why-this-works"><a class="header" href="#why-this-works">Why This Works</a></h3>
<ol>
<li><strong>Conservative</strong>: We might report false violations, but never miss real ones</li>
<li><strong>Correlated signals</strong>: Signals at the same thread position are often topologically nearby with similar timing</li>
<li><strong>Endpoint focus</strong>: We ultimately only care about arrivals at DFF D inputs</li>
</ol>
<h3 id="when-full-accuracy-is-needed"><a class="header" href="#when-full-accuracy-is-needed">When Full Accuracy is Needed</a></h3>
<p>For bit-accurate timing, you would need:</p>
<pre><code class="language-cpp">// 8KB additional shared memory (may exceed limits)
__shared__ u8 shared_arrival[256][32];  // Per-bit arrivals
</code></pre>
<p>This is feasible but significantly increases memory pressure and computation.</p>
<h2 id="implementation-phases"><a class="header" href="#implementation-phases">Implementation Phases</a></h2>
<h3 id="phase-1-cpu-timing-analysis-completed"><a class="header" href="#phase-1-cpu-timing-analysis-completed">Phase 1: CPU Timing Analysis (Completed)</a></h3>
<ul>
<li>Liberty parser for delay extraction</li>
<li>Static timing analysis on AIG</li>
<li>CPU reference simulation with delays</li>
<li>Timing violation detection</li>
</ul>
<h3 id="phase-2-hybrid-gpucpu-completed"><a class="header" href="#phase-2-hybrid-gpucpu-completed">Phase 2: Hybrid GPU+CPU (Completed)</a></h3>
<ul>
<li>GPU performs zero-delay value simulation</li>
<li>CPU performs timing analysis on results</li>
<li>Validates infrastructure without kernel changes</li>
</ul>
<h3 id="phase-3-gpu-arrival-tracking-future"><a class="header" href="#phase-3-gpu-arrival-tracking-future">Phase 3: GPU Arrival Tracking (Future)</a></h3>
<ul>
<li>Add <code>shared_arrival[256]</code> to kernel</li>
<li>Track arrivals during boomerang reduction</li>
<li>Report max arrival at cycle boundaries</li>
<li>Check violations at DFF endpoints</li>
</ul>
<h3 id="phase-4-full-integration-future"><a class="header" href="#phase-4-full-integration-future">Phase 4: Full Integration (Future)</a></h3>
<ul>
<li>Timing violation events via event buffer</li>
<li>Per-cycle timing reports</li>
<li>Integration with output VCD</li>
</ul>
<h2 id="delay-data-encoding"><a class="header" href="#delay-data-encoding">Delay Data Encoding</a></h2>
<h3 id="script-format"><a class="header" href="#script-format">Script Format</a></h3>
<p>The existing boomerang section has padding that can store delay data:</p>
<pre><code>Current format per thread per stage:
  [xora: u32]
  [xorb: u32]
  [orb:  u32]
  [padding: u32]  ← Can store delay here
</code></pre>
<h3 id="packeddelay-structure"><a class="header" href="#packeddelay-structure">PackedDelay Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[repr(C)]
pub struct PackedDelay {
    pub rise_ps: u16,  // Rising edge delay in picoseconds
    pub fall_ps: u16,  // Falling edge delay in picoseconds
}
<span class="boring">}</span></code></pre></pre>
<p>For simplified timing, a single uniform delay constant can be used instead of per-gate delays.</p>
<h2 id="timing-violation-detection"><a class="header" href="#timing-violation-detection">Timing Violation Detection</a></h2>
<h3 id="at-each-cycle-boundary"><a class="header" href="#at-each-cycle-boundary">At Each Cycle Boundary</a></h3>
<p>The GPU kernel checks timing constraints per state word (32 signals) after the boomerang evaluation completes. Arrivals and constraints use <strong>u16 picosecond</strong> values (range 0–65535 ps). Arithmetic is performed in <strong>u32</strong> to avoid overflow when summing arrival + setup:</p>
<pre><code class="language-cpp">// After boomerang completes, before next cycle
// arrival: u16 max accumulated delay for this 32-signal group
// constraint_word: packed [setup_ps:16][hold_ps:16]
u16 setup_ps = constraint_word &gt;&gt; 16;
u16 hold_ps  = constraint_word &amp; 0xFFFF;

// Setup check: skip when arrival == 0 (no data propagated, e.g. first cycle
// or DFF with constant inputs)
if (arrival &gt; 0 &amp;&amp; (u32)arrival + (u32)setup_ps &gt; clock_period_ps) {
    int slack = (int)clock_period_ps - (int)arrival - (int)setup_ps;
    write_event(event_buffer, EVENT_TYPE_SETUP_VIOLATION,
                cycle, io_offset + threadIdx.x,
                (u32)slack, (u32)arrival, (u32)setup_ps);
}

// Hold check: no arrival &gt; 0 guard (hold violations matter even at cycle 0)
if ((u32)arrival &lt; (u32)hold_ps) {
    int slack = (int)arrival - (int)hold_ps;
    write_event(event_buffer, EVENT_TYPE_HOLD_VIOLATION,
                cycle, io_offset + threadIdx.x,
                (u32)slack, (u32)arrival, (u32)hold_ps);
}
</code></pre>
<h3 id="event-buffer-integration"><a class="header" href="#event-buffer-integration">Event Buffer Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum EventType {
    Stop = 0,
    Finish = 1,
    Display = 2,
    AssertFail = 3,
    SetupViolation = 4,   // Timing events
    HoldViolation = 5,
}
<span class="boring">}</span></code></pre></pre>
<p>For full details on interpreting violation reports and tracing violations to source signals, see <a href="timing-violations.html">docs/timing-violations.md</a>.</p>
<h2 id="timing-aware-bit-packing"><a class="header" href="#timing-aware-bit-packing">Timing-Aware Bit Packing</a></h2>
<h3 id="the-problem"><a class="header" href="#the-problem">The Problem</a></h3>
<p>Each thread position holds 32 signals packed into a u32. When tracking timing with one arrival value per thread position, we approximate all 32 signals as having the same arrival time (the maximum).</p>
<p>This approximation is accurate when signals in the same thread have similar timing. But the default placement algorithm uses <strong>first-fit</strong> for bit assignment:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Default: first available slot
for i in 0..hier[selected_level].len() {
    if hier[selected_level][i] == usize::MAX {
        slot_at_level = i;  // First-fit, not timing-aware
        break;
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This can result in signals with very different timing sharing a thread:</p>
<pre><code>Thread 50 (accidental grouping):
  bit 0: level 5,  ~5ps arrival
  bit 1: level 12, ~12ps arrival  ← 7ps difference!
  bit 2: level 6,  ~6ps arrival

Thread 50 (timing-aware grouping):
  bit 0: level 5, ~5ps arrival
  bit 1: level 5, ~5ps arrival    ← similar timing
  bit 2: level 6, ~6ps arrival
</code></pre>
<h3 id="current-timing-correlation"><a class="header" href="#current-timing-correlation">Current Timing Correlation</a></h3>
<p>The placement algorithm already computes <strong>logic levels</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Level = max(level of inputs) + 1
level[node] = max(level[input_a], level[input_b]) + 1;
<span class="boring">}</span></code></pre></pre>
<p>Logic level correlates with timing (more levels = more gate delays), but signals at the same level can still have different actual delays due to:</p>
<ul>
<li>Different gate types (AND2_00_0 vs AND2_11_1)</li>
<li>Different wire loads</li>
<li>Path reconvergence</li>
</ul>
<h3 id="solution-sort-by-timing-before-packing"><a class="header" href="#solution-sort-by-timing-before-packing">Solution: Sort by Timing Before Packing</a></h3>
<p>Before assigning bit positions, sort signals by their estimated arrival time:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Collect nodes at this level
let mut nodes_to_place: Vec&lt;_&gt; = candidates
    .filter(|n| level[n] == selected_level)
    .collect();

// Sort by arrival time (level as proxy, or actual timing if available)
nodes_to_place.sort_by_key(|n| arrival_estimate[n]);

// Place in sorted order - similar timing ends up in same thread
for (slot, node) in nodes_to_place.iter().enumerate() {
    place_bit(..., slot, *node);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="alternative-approaches"><a class="header" href="#alternative-approaches">Alternative Approaches</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Approach</th><th>Complexity</th><th>Effectiveness</th><th>When to Use</th></tr></thead><tbody>
<tr><td><strong>Sort by timing</strong></td><td>Low</td><td>Good</td><td>Default choice</td></tr>
<tr><td>Timing-aware partitioning</td><td>High</td><td>Best</td><td>Large designs</td></tr>
<tr><td>Post-placement swapping</td><td>Medium</td><td>Good</td><td>Fine-tuning</td></tr>
<tr><td>Timing bands</td><td>Low</td><td>Moderate</td><td>Simple heuristic</td></tr>
</tbody></table>
</div>
<h3 id="timing-bands"><a class="header" href="#timing-bands">Timing Bands</a></h3>
<p>Group signals into arrival time bands:</p>
<pre><code>Band 0: 0-10ps   → Threads 0-63
Band 1: 10-20ps  → Threads 64-127
Band 2: 20-30ps  → Threads 128-191
Band 3: 30+ps    → Threads 192-255
</code></pre>
<h3 id="measuring-packing-quality"><a class="header" href="#measuring-packing-quality">Measuring Packing Quality</a></h3>
<p>Diagnostic to measure timing variance per thread:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn analyze_timing_packing(hier: &amp;Hierarchy, arrivals: &amp;[u64]) {
    for thread in 0..256 {
        let times: Vec&lt;_&gt; = get_bits_in_thread(hier, thread)
            .map(|b| arrivals[b])
            .collect();

        let range = times.iter().max() - times.iter().min();
        let variance = compute_variance(&amp;times);

        if range &gt; threshold {
            warn!("Thread {} has {}ps timing spread", thread, range);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="impact-on-approximation-accuracy"><a class="header" href="#impact-on-approximation-accuracy">Impact on Approximation Accuracy</a></h3>
<p>With timing-aware packing:</p>
<ul>
<li><strong>Reduced false positives</strong>: Fewer spurious timing violations from max approximation</li>
<li><strong>Tighter bounds</strong>: Per-thread arrival closer to actual signal arrivals</li>
<li><strong>Better critical path identification</strong>: Max arrival more accurately reflects true critical path</li>
</ul>
<h2 id="performance-expectations"><a class="header" href="#performance-expectations">Performance Expectations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Zero-Delay</th><th>With Timing</th></tr></thead><tbody>
<tr><td>Kernel launches</td><td>N</td><td>N</td></tr>
<tr><td>Shared memory</td><td>3KB</td><td>3.25KB</td></tr>
<tr><td>Registers</td><td>~32</td><td>~36</td></tr>
<tr><td>Instructions/gate</td><td>~5</td><td>~9</td></tr>
<tr><td><strong>Estimated overhead</strong></td><td>-</td><td><strong>15-25%</strong></td></tr>
</tbody></table>
</div>
<p>The overhead is modest because:</p>
<ol>
<li>Timing operations are simple (max, add)</li>
<li>Memory access pattern is identical</li>
<li>No additional synchronization needed</li>
<li>Same parallelism structure</li>
</ol>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><code>src/pe.rs</code> - Partition executor and boomerang stage construction</li>
<li><code>csrc/kernel_v1_impl.cuh</code> - GPU kernel implementation</li>
<li><code>src/flatten.rs</code> - Script generation with timing data</li>
<li><code>src/event_buffer.rs</code> - GPU→CPU event communication</li>
<li><code>src/liberty_parser.rs</code> - Timing library parsing</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="simulation-architecture.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="timing-violations.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="simulation-architecture.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="timing-violations.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
